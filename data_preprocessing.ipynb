{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xDaryamo/NFR-Security-Extraction-Classification/blob/master/data_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZDtS_XYRy-6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import os\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "from tabulate import tabulate\n",
        "from string import punctuation\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1u9VXWGBp2M",
        "outputId": "bf48715b-a871-4387-90d5-5a87dd2e32de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-26 11:39:00.778576: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "\u001b[K     |████████████████████████████████| 460.3 MB 25 kB/s \n",
            "\u001b[K     |████████████████████████████████| 53 kB 2.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 38.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 46.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 182 kB 52.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 45.3 MB/s \n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_trf')\n"
          ]
        }
      ],
      "source": [
        "#!python -m spacy download en_core_web_md\n",
        "!python -m spacy download en_core_web_trf --quiet\n",
        "!pip install spacy-transformers --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CSiEZ-Mg5rrJ"
      },
      "outputs": [],
      "source": [
        "import spacy_transformers\n",
        "nlp = spacy.load(\"en_core_web_trf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WgjHQOuy5jdK"
      },
      "outputs": [],
      "source": [
        "def features(sentence):\n",
        "\n",
        "    \n",
        "    doc = nlp(sentence)\n",
        "    tokens = []\n",
        "    tokens_dep = []\n",
        "    tokens_pos = []\n",
        "\n",
        "    for token in doc:\n",
        "      if str(token) not in punctuation:\n",
        "        if token.ent_type_ == '':\n",
        "          tokens.append(token.text)\n",
        "        else:\n",
        "          tokens.append(token.ent_type_)\n",
        "\n",
        "    for token in doc:\n",
        "      if str(token) not in punctuation:\n",
        "        tokens_dep.append(token.dep_)\n",
        " \n",
        "    for token in doc:\n",
        "        if str(token) not in punctuation:\n",
        "            tokens_pos.append(token.pos_)\n",
        " \n",
        "    return tokens, tokens_dep, tokens_pos "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def is_quote_ok(s):\n",
        "    stack = []\n",
        "    for c in s:\n",
        "        if c in [\"'\", '\"', \"`\"]:\n",
        "            if stack and stack[-1] == c:\n",
        "                stack.pop()\n",
        "            else:\n",
        "                stack.append(c)\n",
        "        else:\n",
        "            # ignore it\n",
        "            pass\n",
        "\n",
        "    return len(stack) == 0"
      ],
      "metadata": {
        "id": "bHce2jJ8Y_Nl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBFrDKPbZf3p"
      },
      "outputs": [],
      "source": [
        "def findWholeWord(w):\n",
        "    return re.compile(r'\\b({0})\\b'.format(w), flags=re.IGNORECASE).search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZtOOZfkqNIQ"
      },
      "outputs": [],
      "source": [
        "def is_member(sentence):\n",
        "  if re.search(\"^(\\(?[0-9]+\\s*)[\\)\\-](\\s+)?\", sentence):\n",
        "    sentence = re.sub(\"^(\\(?[0-9]+\\s*)[\\)\\-](\\s+)?\", '', sentence)\n",
        "    flag = True\n",
        "  elif re.search(\"^([\\-]+)(\\s+)?\", sentence):\n",
        "    sentence = re.sub(\"^([\\-]+)(\\s+)?\", '', sentence)\n",
        "    flag = True\n",
        "  elif re.search(\"^(\\(?[a-zA-Z]*)\\)+(\\s+)?\", sentence):\n",
        "    sentence = re.sub(\"^(\\(?[a-zA-Z]*)\\)+(\\s+)?\", '', sentence)\n",
        "    flag = True\n",
        "  elif re.search(\"^[a-z]\\.+[^g](\\s+)?\", sentence):\n",
        "    sentence = re.sub(\"^[a-z]\\.+[^g](\\s+)?\", '', sentence)\n",
        "    flag = True\n",
        "  elif re.search(\"^(• )+(\\s+)?\", sentence):\n",
        "    sentence = re.sub(\"^(• )+(\\s+)?\", '', sentence)\n",
        "    flag = True\n",
        "  else:\n",
        "    flag = False\n",
        "    \n",
        "  \n",
        "  return flag, sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qafJv5gn1zXJ"
      },
      "outputs": [],
      "source": [
        "#Titoli paragrafi e sezioni\n",
        "def is_title(sentence):\n",
        "  return re.search(\"^((I|i)(N|n)|(D|d)(C|c))?\\.?([0-9])([\\.0-9]+)\", sentence) or re.search(\"^[A-Za-z]+\\s+((S|s)ection)\", sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AqtEFDkb052t"
      },
      "outputs": [],
      "source": [
        "def is_skippable(sentence):\n",
        "\n",
        "  #ID delle User Stories\n",
        "  if re.search(\"^(User Story: )?US[0-9]+(\\.*[0-9])*\", sentence) or re.search(\"^(Technical Story: )?TS[0-9]+(\\.[0-9]*)*\", sentence):\n",
        "    return True\n",
        "    \n",
        "  #Solo caratteri speciali\n",
        "  elif re.search(\"^[\\W_]+$\", sentence) or re.search(\"^([\\|\\.\\;\\,\\@][\\d\\s\\w]?)+\", sentence) or re.search(\"^\\s*\\+\", sentence):\n",
        "    return True\n",
        "\n",
        "  #Tutte le frasi composte da solo 2 parole\n",
        "  elif len(re.findall('\\w+', sentence)) <= 2:\n",
        "    return True\n",
        "\n",
        "  #Le frasi 'None at present.' ricorrenti nel dataset\n",
        "  elif sentence == \"None at present.\":\n",
        "    return True\n",
        "\n",
        "  #Url\n",
        "  elif re.search(\"^https?:\\\\/\\\\/(?:www\\\\.)?[-a-zA-Z0-9@:%._\\\\+~#=]{1,256}\\\\.[a-zA-Z0-9()]{1,6}\\\\b(?:[-a-zA-Z0-9()@:%_\\\\+.~#?&\\\\/=]*)$\", sentence) or \\\n",
        "        (re.search(\"^([a-z\\-\\_]+\\.)+[a-z]+\", sentence) and not re.search(\"^(e\\.g\\.|E\\.g\\.)\\s*\", sentence)):\n",
        "    return True\n",
        "\n",
        "  #Didascalie tabelle e immagini\n",
        "  elif re.search(\"^(Figure|Table)\\s?[0-9]\", sentence):\n",
        "    return True\n",
        "\n",
        "  #Testi \"See also\"\n",
        "  elif re.search(\"^(See also|see also)\", sentence):\n",
        "    return True\n",
        "\n",
        "  #Email\n",
        "  elif re.search(\"^[a-zA-Z0-9.! #$%&'*+/=? ^_`{|}~-]+@[a-zA-Z0-9-]+(?:\\.[a-zA-Z0-9-]+)*$\", sentence):\n",
        "    return True\n",
        "\n",
        "  #Log message\n",
        "  elif re.search(\"^((L|l)og (m|M)essage|(f|F)eature (r|R)equest|(F|f)eature (I|i)(d|D))\", sentence):\n",
        "    return True\n",
        "\n",
        "  #Informazioni temporali\n",
        "  elif re.search(\"^(build date:)\", sentence) or \\\n",
        "        re.search(\"(?:\\\"|\\')?((J|j)an(?:uary)?|(F|f)eb(?:ruary)?|(M|m)ar(?:ch)?|(A|a)pr(?:il)?|(M|m)ay|(J|j)un(?:e)?|(J|j)ul(?:y)?|(A|a)ug(?:ust)?|(S|s)ept(?:ember)?|(S|s)ep(?:tember)?|(O|o)ct(?:ober)?|(N|n)ov(?:ember)?|(D|d)ec(?:ember)?)\\s+(\\d{1,2}(st|nd|rd|th)?)\\,?\\s+((\\d{4})\\s?)?((\\d{1,2}):\\d{1,2}\\s+(am|AM|Am|pm|Pm|PM)?)?\", sentence) or \\\n",
        "        re.search(\"\\d{4,4}-\\d{1,2}-\\d{1,2}\\s+((\\d{1,2}):\\d{1,2}\\s+(am|AM|Am|pm|Pm|PM)?)?\", sentence) or \\\n",
        "        re.search(\"^build date:\", sentence) or re.search(\"^(\\d(-| to | or )?\\s?)+((d|D)ays?|(m|M)onths? | (y|Y)ears? | (w|W)eeks?)\", sentence) or \\\n",
        "        re.search(\"^[\\d]+\\s(business )?(days?|weeks?|years?|months?)\", sentence):\n",
        "    return True\n",
        "  \n",
        "  #Frasi che indicano errori (iniziano con \"issue x\")\n",
        "  elif re.search(\"^(Issues?)\\s+\\d+\", sentence):\n",
        "    return True\n",
        "\n",
        "  elif re.search(\"^(org.|sun.|javax.|oscar.|net.|lang.|doinhibernate|qcvl.|qeh.|qgoatway.)\", sentence):\n",
        "    return True\n",
        "\n",
        "  elif re.search(\"^(Please note)[^:]*:$\", sentence) or re.search(\"(go to):?\\s*(https?:\\/\\/)?(\\w\\w\\w.)?[a-zA-z]+\", sentence):\n",
        "    return True\n",
        "\n",
        "  elif re.search(\"^(login|log in|logon|log on|logout|log out|(c|C)urrent functionality:|(r|R)equired new functionality:|WL:|(I|i)ntake \\d*)\", sentence):\n",
        "    return True\n",
        "\n",
        "  #Metodi o funzioni\n",
        "  elif re.search(\"^(insert into|include)\", sentence) or re.search(\"^([A-Za-z]+)+\\([\\W\\w\\d]*\\);?\", sentence) or re.search(\"^(add|Add|ADD)\", sentence) or re.search(\"^((C|c)lick on)\", sentence) or re.search(\"^((G|g)et)\", sentence) or \\\n",
        "        re.search(\"^(O?SCAR)\", sentence) or re.search(\"^((P|p)lease)\", sentence) or re.search(\"^((S|s)elect)\", sentence) or re.search(\"^((M|m)ove)\", sentence) or re.search(\"^((S|s)etup:)\", sentence) or\\\n",
        "        re.search(\"^((C|c)hange)\", sentence) or re.search(\"^((S|s)how)\", sentence) or re.search(\"^((U|u)pdate)\", sentence) or re.search(\"^((R|r)emove)\", sentence) or re.search(\"^((I|i)nclude)\", sentence) or\\\n",
        "        re.search(\"^[\\'\\\"\\`]?[A-Za-z\\s]+[\\'\\\"\\`]?\\=\\s*[\\'\\\"\\`]?\\_[\\w\\d]+[\\'\\\"\\`]?\", sentence) or re.search(\"^[\\w\\d\\s]+(\\-\\>)[\\w\\d\\s]+[\\.\\;\\?\\!]?$\", sentence) or re.search(\"^((F|f)ile (A|a)dd(ed)?:?)\", sentence) or\\\n",
        "        re.search(\"^[A-Za-z\\s]+\\=[A-Za-z\\s\\W]+$\", sentence) or re.search(\"^((B|b)uild (T|t)ag)\\s?\\:\", sentence):\n",
        "    return True\n",
        "\n",
        "  elif re.search(\"^\\d(st|nd|rd):?\", sentence):\n",
        "    return True\n",
        "  else:\n",
        "    return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_qwqeuz0nNlI"
      },
      "outputs": [],
      "source": [
        "def clean_data(sentence, s_type, old_sentence, list_start):\n",
        "  \n",
        "  #Rimuoviamo i caratteri � dalle stringhe e gli spazi all'inizio e alla fine\n",
        "  sentence = sentence.replace('�', '').replace(\"\", '').replace(\"\\‘\", \"\\\"\").replace(\"\\’\", \"\\\"\").replace(\"\\“\", \"\\\"\").replace(\"\\”\", \"\\\"\")\n",
        "  old_sentence = old_sentence.replace('�', '').replace(\"\", '').replace(\"\\‘\", \"\\\"\").replace(\"\\’\", \"\\\"\").replace(\"\\“\", \"\\\"\").replace(\"\\”\", \"\\\"\")\n",
        "  sentence = sentence.strip(\"\\\"\").strip(\"\\'\").strip(\"\\`\").strip()\n",
        "  old_sentence = old_sentence.strip(\"\\\"\").strip(\"\\'\").strip(\"\\`\").strip()\n",
        "\n",
        "  \n",
        "  \n",
        "  if re.search(\"^\\([\\w\\W]*\\)$\", sentence):\n",
        "    sentence = sentence.strip().strip(\"(\").strip(\")\")\n",
        "  elif re.search(\"^\\([\\w\\W]*\\)$\", old_sentence):\n",
        "    old_sentence = old_sentence.strip().strip(\"(\").strip(\")\")\n",
        "\n",
        "  flag_member, new_sentence = is_member(old_sentence)\n",
        "  #Se è un titolo\n",
        "  if (s_type == 'TITLE' or is_title(old_sentence)) and not flag_member:\n",
        "    #print(\"SKIPPO: \" + sentence)\n",
        "    return None, None\n",
        "\n",
        "\n",
        "  #Se è un inizio di una lista \n",
        "  elif s_type == 'LIST_START' and not re.search(\"^[\\W_]+$\", sentence):\n",
        "    list_start = sentence.strip(\"-\")\n",
        "    return None, list_start\n",
        "  \n",
        "  \n",
        "\n",
        "\n",
        "  #Se è il membro di una lista\n",
        "  if (s_type == 'LIST_MEMBER' or flag_member) and not re.search(\"^[\\W_]+$\", sentence):\n",
        "    if list_start == None:\n",
        "      sentence = new_sentence.strip()\n",
        "    else: \n",
        "      sentence = list_start + ' ' + new_sentence\n",
        "\n",
        "\n",
        "\n",
        "  if sentence != None:\n",
        "    #Se la frase non rispetta certi requisiti non viene considerata\\\n",
        "    if is_skippable(sentence):\n",
        "      #print(\"SKIPPO: \" + sentence)\n",
        "      return None, list_start\n",
        "    else:   \n",
        "      sentence = re.sub('^[\\\"\\'\\`][\\\"\\'\\`][\\.\\;\\,]?$', '', sentence)\n",
        "      if(not is_quote_ok(sentence)):\n",
        "        sentence = sentence.replace(\"\\\"\", '').replace(\"\\'\", '').replace(\"\\`\", '')\n",
        "      sentence = re.sub('[\\;\\.\\,\\:]$', '', sentence)\n",
        "      sentence = re.sub('[\\s][\\s]+', ' ', sentence)\n",
        "      sentence = re.sub('(\\_|-){2,255}','', sentence)\n",
        "      if sentence[-1] != '?' and sentence[-1] != '!':\n",
        "        sentence = sentence + \".\"\n",
        "      sentence = sentence[0].upper() + sentence[1:]\n",
        "\n",
        "  \n",
        "  return sentence, list_start\n",
        " \n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tEOMPrwBjXX"
      },
      "outputs": [],
      "source": [
        "from pandas.io.common import dataclasses\n",
        "\n",
        "root = '/content/drive/MyDrive/Security Extraction/'\n",
        "\n",
        "keywords = pd.read_excel(root + \"/security_words.xlsx\").values.tolist()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIbtM1pWQ1FO"
      },
      "source": [
        "# Dataset da drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUdg9nMA5-e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "outputId": "7d260154-0c9a-4c47-b75e-af383e18d649"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing CCHIT Certified 2011 Ambulatory EHR Criteria 20110517_PUBLISH.json ...\n",
            "Processing EHR-Privacy-Security-Requirements_PUBLISH.json ...\n",
            "Processing featureRequests - for annotation -PUBLISH.json ...\n",
            "Processing HL7_Functional_Profile - PUBLISH.json ...\n",
            "Processing nursing_ehr_business_and_functional_elements_june__2012_PUBLISH.json ...\n",
            "Processing VLER UserStories Combined_PUBLISH.json ...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            Sentence  \\\n",
              "0  The system shall create a single patient recor...   \n",
              "1  The system shall associate (store and link) ke...   \n",
              "2  The system shall provide the ability to store ...   \n",
              "3  The system shall provide a field which will id...   \n",
              "4  The system shall provide the ability to merge ...   \n",
              "\n",
              "                                            Entities  \\\n",
              "0  [The, system, shall, create, a, single, patien...   \n",
              "1  [The, system, shall, associate, store, and, li...   \n",
              "2  [The, system, shall, provide, the, ability, to...   \n",
              "3  [The, system, shall, provide, a, field, which,...   \n",
              "4  [The, system, shall, provide, the, ability, to...   \n",
              "\n",
              "                                        Dependencies  \\\n",
              "0  [det, nsubj, aux, ROOT, det, amod, compound, d...   \n",
              "1  [det, nsubj, aux, ROOT, dobj, cc, conj, compou...   \n",
              "2  [det, nsubj, aux, ROOT, det, dobj, aux, acl, a...   \n",
              "3  [det, nsubj, aux, ROOT, det, dobj, nsubj, aux,...   \n",
              "4  [det, nsubj, aux, ROOT, det, dobj, aux, acl, c...   \n",
              "\n",
              "                                     Parts of Speech   File  \\\n",
              "0  [DET, NOUN, AUX, VERB, DET, ADJ, NOUN, NOUN, A...  CCHIT   \n",
              "1  [DET, NOUN, AUX, VERB, NOUN, CCONJ, NOUN, NOUN...  CCHIT   \n",
              "2  [DET, NOUN, AUX, VERB, DET, NOUN, PART, VERB, ...  CCHIT   \n",
              "3  [DET, NOUN, AUX, VERB, DET, NOUN, PRON, AUX, V...  CCHIT   \n",
              "4  [DET, NOUN, AUX, VERB, DET, NOUN, PART, VERB, ...  CCHIT   \n",
              "\n",
              "                                     Categories Security Words Security  \n",
              "0                             [CONFIDENTIALITY]           none        1  \n",
              "1    [ACCESS_CONTROL_IDENTITY, CONFIDENTIALITY]           none        1  \n",
              "2                     [ACCESS_CONTROL_IDENTITY]           none        1  \n",
              "3                                          none           none        0  \n",
              "4  [INTEGRITY, CONFIDENTIALITY, ACCOUNTABILITY]           none        1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-48f3ec7f-2a51-4a05-ba45-a396dc561a09\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Entities</th>\n",
              "      <th>Dependencies</th>\n",
              "      <th>Parts of Speech</th>\n",
              "      <th>File</th>\n",
              "      <th>Categories</th>\n",
              "      <th>Security Words</th>\n",
              "      <th>Security</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The system shall create a single patient recor...</td>\n",
              "      <td>[The, system, shall, create, a, single, patien...</td>\n",
              "      <td>[det, nsubj, aux, ROOT, det, amod, compound, d...</td>\n",
              "      <td>[DET, NOUN, AUX, VERB, DET, ADJ, NOUN, NOUN, A...</td>\n",
              "      <td>CCHIT</td>\n",
              "      <td>[CONFIDENTIALITY]</td>\n",
              "      <td>none</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The system shall associate (store and link) ke...</td>\n",
              "      <td>[The, system, shall, associate, store, and, li...</td>\n",
              "      <td>[det, nsubj, aux, ROOT, dobj, cc, conj, compou...</td>\n",
              "      <td>[DET, NOUN, AUX, VERB, NOUN, CCONJ, NOUN, NOUN...</td>\n",
              "      <td>CCHIT</td>\n",
              "      <td>[ACCESS_CONTROL_IDENTITY, CONFIDENTIALITY]</td>\n",
              "      <td>none</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The system shall provide the ability to store ...</td>\n",
              "      <td>[The, system, shall, provide, the, ability, to...</td>\n",
              "      <td>[det, nsubj, aux, ROOT, det, dobj, aux, acl, a...</td>\n",
              "      <td>[DET, NOUN, AUX, VERB, DET, NOUN, PART, VERB, ...</td>\n",
              "      <td>CCHIT</td>\n",
              "      <td>[ACCESS_CONTROL_IDENTITY]</td>\n",
              "      <td>none</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The system shall provide a field which will id...</td>\n",
              "      <td>[The, system, shall, provide, a, field, which,...</td>\n",
              "      <td>[det, nsubj, aux, ROOT, det, dobj, nsubj, aux,...</td>\n",
              "      <td>[DET, NOUN, AUX, VERB, DET, NOUN, PRON, AUX, V...</td>\n",
              "      <td>CCHIT</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The system shall provide the ability to merge ...</td>\n",
              "      <td>[The, system, shall, provide, the, ability, to...</td>\n",
              "      <td>[det, nsubj, aux, ROOT, det, dobj, aux, acl, c...</td>\n",
              "      <td>[DET, NOUN, AUX, VERB, DET, NOUN, PART, VERB, ...</td>\n",
              "      <td>CCHIT</td>\n",
              "      <td>[INTEGRITY, CONFIDENTIALITY, ACCOUNTABILITY]</td>\n",
              "      <td>none</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-48f3ec7f-2a51-4a05-ba45-a396dc561a09')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-48f3ec7f-2a51-4a05-ba45-a396dc561a09 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-48f3ec7f-2a51-4a05-ba45-a396dc561a09');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "from pandas.io.common import dataclasses\n",
        "dataset_path = root + '/dataset'\n",
        "df = pd.DataFrame(columns=[\"Sentence\", \"Entities\", \"Dependencies\", \"Parts of Speech\", \"File\", \"Categories\", \"Security Words\", \"Security\"])\n",
        "\n",
        "\n",
        "counter = 0\n",
        "list_start = None\n",
        "for file in os.listdir(dataset_path):\n",
        "    print(\"Processing \" + file + \" ...\")\n",
        "    with open(dataset_path+'/'+file) as f:\n",
        "      data = json.load(f)\n",
        "      \n",
        "    for i in range(0, len(data['content'])):\n",
        "      current_item = data['content'][i]\n",
        "      sentence = current_item['parserSentence']\n",
        "      full_sentence = current_item['sentence']\n",
        "      s_type = current_item['sentenceType']\n",
        "      ojective = current_item['securityObjectiveAnnotations']\n",
        "      sentence, list_start = clean_data(sentence, s_type, full_sentence,  list_start)\n",
        "\n",
        "\n",
        "      if not sentence:\n",
        "        continue\n",
        "\n",
        "      #print(sentence)\n",
        "\n",
        "      entities, dependencies, pos = features(sentence)\n",
        "      df.loc[counter, \"Sentence\"] = sentence\n",
        "      df.loc[counter,\"Entities\"] = entities\n",
        "      df.loc[counter,\"Dependencies\"] = dependencies\n",
        "      df.loc[counter,\"Parts of Speech\"] = pos\n",
        "      df.loc[counter,\"File\"] = current_item['documentID']\n",
        "\n",
        "\n",
        "      if not ojective or (len(ojective)) == 1 and (ojective[0][\"securityObjective\"] == 'DATABASE' or \\\n",
        "                                                    ojective[0][\"securityObjective\"] == 'TECHNICAL' or \\\n",
        "                                                    ojective[0][\"securityObjective\"] == 'MANAGEMENT'):\n",
        "\n",
        "        df.loc[counter,\"Security\"] = 0\n",
        "        df.loc[counter, \"Categories\"] = \"none\"\n",
        "\n",
        "      else:\n",
        "        df.loc[counter,\"Security\"] = 1\n",
        "        categories = []\n",
        "        for item in ojective:\n",
        "          if item[\"securityObjective\"] != 'DATABASE' and item[\"securityObjective\"] != 'TECHNICAL' and item[\"securityObjective\"] != 'MANAGEMENT':\n",
        "            if item[\"securityObjective\"] == 'AVAILABILITY_SURVIVABILITY':\n",
        "              if 'AVAILABILITY' not in categories:\n",
        "                categories.append('AVAILABILITY')\n",
        "            elif item[\"securityObjective\"] == 'INTEGRITY_IMMUNITY':\n",
        "              if 'INTEGRITY' not in categories:\n",
        "                categories.append('INTEGRITY')\n",
        "            else:\n",
        "              categories.append(item[\"securityObjective\"])\n",
        "\n",
        "        df.loc[counter, \"Categories\"] = categories\n",
        "\n",
        "      security_words = []\n",
        "      for keyword in keywords:\n",
        "        if findWholeWord(keyword[0])(sentence.lower()):\n",
        "              security_words.append(keyword[0]) \n",
        "        if not security_words:\n",
        "          df.loc[counter, \"Security Words\"] = 'none'\n",
        "        else:\n",
        "          df.loc[counter, \"Security Words\"] = security_words\n",
        "\n",
        "      counter+=1\n",
        "\n",
        "df = df.drop_duplicates(subset=['Sentence'])\n",
        "df.head()\n",
        "   \n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QfkTHnmsCVau"
      },
      "outputs": [],
      "source": [
        "from pandas.io.common import dataclasses\n",
        "df = pd.DataFrame(columns=[\"Sentence\", \"Entities\", \"Dependencies\", \"Parts of Speech\", \"File\", \"Categories\", \"Security Words\", \"Security\"])\n",
        "\n",
        "\n",
        "counter = 0\n",
        "list_start = None\n",
        "for file in os.listdir('./dataset'):\n",
        "    print(\"Processing \" + file + \" ...\")\n",
        "    with open('./dataset/'+file) as f:\n",
        "      data = json.load(f)\n",
        "      \n",
        "    for i in range(0, len(data['content'])):\n",
        "      current_item = data['content'][i]\n",
        "      sentence = current_item['parserSentence']\n",
        "      full_sentence = current_item['sentence']\n",
        "      s_type = current_item['sentenceType']\n",
        "\n",
        "      sentence, list_start = clean_data(sentence, s_type, full_sentence,  list_start)\n",
        "\n",
        "\n",
        "      if not sentence:\n",
        "        continue\n",
        "\n",
        "      #print(sentence)\n",
        "\n",
        "\n",
        "      entities, dependencies, pos = features(sentence)\n",
        "      df.loc[counter, \"Sentence\"] = sentence\n",
        "      df.loc[counter,\"Entities\"] = entities\n",
        "      df.loc[counter,\"Dependencies\"] = dependencies\n",
        "      df.loc[counter,\"Parts of Speech\"] = pos\n",
        "      df.loc[counter,\"File\"] = current_item['documentID']\n",
        "\n",
        "      if not current_item['securityObjectiveAnnotations']:\n",
        "        df.loc[counter,\"Security\"] = 0\n",
        "        df.loc[counter, \"Categories\"] = \"none\"\n",
        "      else:\n",
        "        df.loc[counter,\"Security\"] = 1\n",
        "        categories = []\n",
        "        for j in range(0, len(current_item['securityObjectiveAnnotations'])):\n",
        "          if current_item['securityObjectiveAnnotations'][j][\"securityObjective\"] != 'DATABASE':\n",
        "            categories.append(current_item['securityObjectiveAnnotations'][j][\"securityObjective\"])\n",
        "        df.loc[counter, \"Categories\"] = categories\n",
        "\n",
        "      security_words = []\n",
        "      for keyword in keywords:\n",
        "        if findWholeWord(keyword[0])(sentence.lower()):\n",
        "              security_words.append(keyword[0]) \n",
        "        if not security_words:\n",
        "          df.loc[counter, \"Security Words\"] = 'none'\n",
        "        else:\n",
        "          df.loc[counter, \"Security Words\"] = security_words\n",
        "\n",
        "      counter+=1\n",
        "\n",
        "df = df.drop_duplicates(subset=['Sentence'])\n",
        "df.head()\n",
        "   \n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJoYdZgH2esh"
      },
      "source": [
        "# Esportazione del dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qz8Cka5bTcOU"
      },
      "outputs": [],
      "source": [
        "df.to_excel('/content/drive/MyDrive/Security Extraction/dataset.xlsx',index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UDfDpWsTV3N"
      },
      "source": [
        "# Esempio con una frase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Rsj2-1Kw1pd"
      },
      "outputs": [],
      "source": [
        "#df.loc[df['Security'] == 'TRUE'].iloc[0,0]\n",
        "nfr = \"The specifics of this issue is not addressed by any of the requirements, although Privacy Requirement 8, Privacy Requirement 9, Privacy Requirement 10, Privacy Requirement 11, and Privacy Requirement 12 specify that consent data be captured by POS systems and transmitted to the EHRi when transmitting the underlying PHI. Facebook\"\n",
        "doc = nlp(nfr)\n",
        "displacy.render(doc, style='ent', jupyter=True)\n",
        "displacy.render(doc, style='dep', jupyter=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1fqsvkYnuUMr"
      },
      "outputs": [],
      "source": [
        "data = [] \n",
        "for token in doc:\n",
        "    if str(token) not in punctuation:\n",
        "        data.append([token.text, token.pos_, token.dep_])\n",
        "\n",
        "print(tabulate(data, headers=[\"Text\", \"Part of speech\", \"Dependency\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OfG8AfzUYk1u"
      },
      "outputs": [],
      "source": [
        "df = df.drop_duplicates(subset=['Sentence'])\n",
        "df.head(25)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "string=\"client search = \\'_PMMclientsearch\\'\"\n",
        "print(string.strip(\"\\\"\").strip(\"\\'\").strip(\"\\`\").strip())\n"
      ],
      "metadata": {
        "id": "heKOMJY2QX91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd2f39af-7685-4c41-ff8f-423c2f8b3995"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "client search = '_PMMclientsearch\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1TYQtpDJfiqNZL-ZBS8cUVKSAyw25ugak",
      "authorship_tag": "ABX9TyPXyiTzd7wOem2a0Wtnrlhr",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}